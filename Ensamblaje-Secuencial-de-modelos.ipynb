{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e983b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5aadc5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "house = pd.read_csv('house_prices.csv')\n",
    "parkinson = pd.read_csv('parkinsons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ffc19765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas categóricas en house: ['Condition2', 'LandContour', 'HouseStyle', 'GarageType', 'FireplaceQu', 'Alley', 'MSZoning', 'CentralAir', 'GarageCond', 'Exterior2nd', 'BsmtFinType2', 'GarageQual', 'ExterQual', 'PavedDrive', 'LotShape', 'KitchenQual', 'SaleType', 'BsmtExposure', 'ExterCond', 'BsmtQual', 'MiscFeature', 'PoolQC']\n"
     ]
    }
   ],
   "source": [
    "# Guardamos los atributos categoricos para pasarlos a numéricos\n",
    "cat_cols = house.select_dtypes(include=['object']).columns.tolist()\n",
    "print(\"Columnas categóricas en house:\", cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab7541c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificamos las variables categóricas, ponemos usamos drop_first=True para eliminar la primera categoría de cada variable y evitar la multicolinealidad\n",
    "house_enc = pd.get_dummies(house, columns=cat_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae28ffe",
   "metadata": {},
   "source": [
    "Separar features y target en house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a2ea5d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones X_house: (560, 109)\n",
      "Dimensiones y_house: (560,)\n"
     ]
    }
   ],
   "source": [
    "# Separamos las variables y la variable objetivo\n",
    "X_house = house_enc.drop('SalePrice', axis=1)\n",
    "y_house = house_enc['SalePrice']\n",
    "print(\"Dimensiones X_house:\", X_house.shape)\n",
    "print(\"Dimensiones y_house:\", y_house.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ce5436",
   "metadata": {},
   "source": [
    "Para Parkinsons no hay categóricas, solo separamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "210040fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones X_parkinson: (2000, 19)\n",
      "Dimensiones y_parkinson: (2000,)\n"
     ]
    }
   ],
   "source": [
    "X_parkinson = parkinson.drop('total_UPDRS', axis=1)\n",
    "y_parkinson = parkinson['total_UPDRS']\n",
    "print(\"Dimensiones X_parkinson:\", X_parkinson.shape)\n",
    "print(\"Dimensiones y_parkinson:\", y_parkinson.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d423696a",
   "metadata": {},
   "source": [
    "Dividimos en datos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2ceda06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House split: (448, 109) (112, 109) (448,) (112,)\n"
     ]
    }
   ],
   "source": [
    "Xh_train, Xh_test, yh_train, yh_test = train_test_split(\n",
    "    X_house, y_house, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"House split:\", Xh_train.shape, Xh_test.shape, yh_train.shape, yh_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e29d8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinsons split: (1600, 19) (400, 19) (1600,) (400,)\n"
     ]
    }
   ],
   "source": [
    "Xp_train, Xp_test, yp_train, yp_test = train_test_split(\n",
    "    X_parkinson, y_parkinson, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Parkinsons split:\", Xp_train.shape, Xp_test.shape, yp_train.shape, yp_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0ee894af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialEnsembleRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,\n",
    "                 # Estimador a usar\n",
    "                 estimator=None,\n",
    "                 # Número de modelos a entrenar\n",
    "                 n_estimators=50,\n",
    "                 # Proporción del tamaño de la datos para cada modelo\n",
    "                 sample_size=0.8,\n",
    "                 # Tasa de aprendizaje\n",
    "                 lr=0.1,\n",
    "                 # Semilla para la aleatoriedad\n",
    "                 random_state=None,\n",
    "                 # Parámetros del estimador como max_depth, min_samples_split, etc.\n",
    "                 max_depth=None):\n",
    "        self.estimator = estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.sample_size = sample_size\n",
    "        self.lr = lr\n",
    "        self.random_state = random_state\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #\n",
    "        self.init_prediction_ = np.mean(y)\n",
    "        # Lista para almacenar los modelos entrenados\n",
    "        self.models = []\n",
    "        # Guardo el número de muestras\n",
    "        n_samples = X.shape[0]\n",
    "        # Inicializamos las predicciones a cero\n",
    "        pred = np.full(shape=n_samples, fill_value=self.init_prediction_)\n",
    "        # Inicializamos el generador aleatorio\n",
    "        rng = check_random_state(self.random_state)\n",
    "        \n",
    "        for i in range(self.n_estimators):\n",
    "            #Calculo el residuo actual\n",
    "            resid = y - pred\n",
    "            \n",
    "            # Creo el submodelo con los datos muestreados y los residuos como objetivos\n",
    "            model = clone(self.estimator)\n",
    "            if hasattr(model, \"random_state\"):\n",
    "                model.set_params(random_state=self.random_state)\n",
    "            # Si hay estimador_params, los aplico al modelo\n",
    "            if self.max_depth is not None:\n",
    "                model.set_params(max_depth=self.max_depth)\n",
    "\n",
    "            # Tomo una muesta aleatoria de los datos\n",
    "            k = int(self.sample_size * n_samples)\n",
    "            # Como no hay reemplazo, replace=False\n",
    "            idx = rng.choice(n_samples, k, replace=False)\n",
    "            X_sub = X.iloc[idx]\n",
    "            y_sub = resid.iloc[idx] if hasattr(resid, \"iloc\") else resid[idx]\n",
    "\n",
    "            \n",
    "            model.fit(X_sub, y_sub)\n",
    "            # Almaceno el modelo entrenado\n",
    "            self.models.append(model)\n",
    "            # Actualizo las predicciones\n",
    "            pred += self.lr * model.predict(X)\n",
    "        return self\n",
    "\n",
    "#Devolvemos la prediccion final sumando uno a uno y multiplicando por la tasa de aprendizaje\n",
    "    def predict(self, X):\n",
    "        pred = np.full(shape=X.shape[0], fill_value=self.init_prediction_)\n",
    "        for m in self.models:\n",
    "            pred += self.lr * m.predict(X)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c59e09",
   "metadata": {},
   "source": [
    "Evaluar Housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae5c0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_h = SequentialEnsembleRegressor(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=50,\n",
    "    sample_size=0.8,\n",
    "    lr=0.1,\n",
    "    random_state=42,\n",
    "    max_depth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37757d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House R²: 0.6951221002784407\n",
      "House MAE: 29233.46451825404\n"
     ]
    }
   ],
   "source": [
    "ens_h.fit(Xh_train, yh_train)\n",
    "yh_pred = ens_h.predict(Xh_test)\n",
    "print(\"House R²:\", r2_score(yh_test, yh_pred))\n",
    "print(\"House MAE:\", mean_absolute_error(yh_test, yh_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c243067",
   "metadata": {},
   "source": [
    "Evaluar parkingson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f629cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_p = SequentialEnsembleRegressor(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=50,\n",
    "    sample_size=0.8,\n",
    "    lr=0.1,\n",
    "    random_state=42,\n",
    "    max_depth=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d6b85bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinsons R²: 0.6699741811362365\n",
      "Parkinsons MAE: 4.825034392514188\n"
     ]
    }
   ],
   "source": [
    "ens_p.fit(Xp_train, yp_train)\n",
    "yp_pred = ens_p.predict(Xp_test)\n",
    "print(\"Parkinsons R²:\", r2_score(yp_test, yp_pred))\n",
    "print(\"Parkinsons MAE:\", mean_absolute_error(yp_test, yp_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9266e95",
   "metadata": {},
   "source": [
    "Validación cruzada y busqueda de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a150560d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House CV R²: [0.72356832 0.75864956 0.76608286 0.78143207 0.77203406] → Media: 0.7603533739391801\n"
     ]
    }
   ],
   "source": [
    "# Se dividen los datos en 5 particiones, barajamos los datos y usamos la semilla 42 para reproducibilidad\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(\n",
    "    SequentialEnsembleRegressor(\n",
    "        # Estimador a usar\n",
    "        estimator=DecisionTreeRegressor(max_depth=3),\n",
    "        n_estimators=50, sample_size=0.8, lr=0.1, random_state=42\n",
    "    ),\n",
    "    Xh_train, yh_train,\n",
    "    scoring='r2', cv=cv, n_jobs=-1\n",
    "    # Se entrena el modelo con 4 de las 5 particiones y se evalua la restante usando R² como métrica\n",
    "    # Repite el proceso 5 veces, cada vez con una partición diferente como test\n",
    "    # Pongo n_jobs -1 para usar todos los núcleos disponibles en la CPU\n",
    ")\n",
    "print(\"House CV R²:\", scores, \"→ Media:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56798fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo base con hiperparámetros iniciales\n",
    "base_model = SequentialEnsembleRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=3),\n",
    "    n_estimators=50,\n",
    "    sample_size=0.8,\n",
    "    lr=0.1,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7be4e4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House CV R² scores: [0.72353283 0.77689812 0.77236508 0.78746294 0.77894553]\n",
      "Media R²: 0.7678408998095679\n"
     ]
    }
   ],
   "source": [
    "scores_house = cross_val_score(\n",
    "    base_model, Xh_train, yh_train,\n",
    "    scoring='r2', cv=cv, n_jobs=-1\n",
    ")\n",
    "print(\"House CV R² scores:\", scores_house)\n",
    "print(\"Media R²:\", scores_house.mean())\n",
    "# Si los modelos se parecen entre si el modelo es estable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15964a09",
   "metadata": {},
   "source": [
    "Parkinson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f2816d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinsons CV R² scores: [0.64242144 0.65989829 0.63023465 0.65740071 0.67936077]\n",
      "Media R²: 0.6538631707613632\n"
     ]
    }
   ],
   "source": [
    "scores_parkinson = cross_val_score(\n",
    "    base_model, Xp_train, yp_train,\n",
    "    scoring='r2', cv=cv, n_jobs=-1\n",
    ")\n",
    "print(\"Parkinsons CV R² scores:\", scores_parkinson)\n",
    "print(\"Media R²:\", scores_parkinson.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b034a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76742f22",
   "metadata": {},
   "source": [
    "Busqueda manual de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da2a1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_seq_ensemble(X, y, param_grid, cv):\n",
    "    results = []\n",
    "    for n in param_grid['n_estimators']:\n",
    "        for lr in param_grid['lr']:\n",
    "            for s in param_grid['sample_size']:\n",
    "                for md in param_grid['max_depth']:\n",
    "                    model = SequentialEnsembleRegressor(\n",
    "                        estimator=DecisionTreeRegressor(),\n",
    "                        n_estimators=n,\n",
    "                        lr=lr,\n",
    "                        sample_size=s,\n",
    "                        random_state=42,\n",
    "                        max_depth=md\n",
    "                    )\n",
    "                    scores = cross_val_score(\n",
    "                        model, X, y,\n",
    "                        scoring='r2', cv=cv, n_jobs=-1\n",
    "                    )\n",
    "                    results.append({\n",
    "                        'n_estimators': n,\n",
    "                        'lr': lr,\n",
    "                        'sample_size': s,\n",
    "                        'max_depth': md,\n",
    "                        'r2_mean': scores.mean()\n",
    "                    })\n",
    "\n",
    "    df_results = pd.DataFrame(results)\n",
    "    df_results = df_results.sort_values('r2_mean', ascending=False).reset_index(drop=True)\n",
    "    print(\"Top 10 combos:\\n\", df_results.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f53928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combos:\n",
      "    n_estimators   lr  sample_size  max_depth   r2_mean\n",
      "0           100  0.2          0.8          3  0.790717\n",
      "1           100  0.1          0.6          3  0.790011\n",
      "2           100  0.2          1.0          3  0.788360\n",
      "3           100  0.1          1.0          3  0.786865\n",
      "4           100  0.1          1.0          5  0.784163\n",
      "5            50  0.2          0.8          3  0.783979\n",
      "6            50  0.2          1.0          3  0.783529\n",
      "7           100  0.2          1.0          5  0.782545\n",
      "8            50  0.2          1.0          5  0.780902\n",
      "9           100  0.1          0.6          7  0.778543\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'lr': [0.01, 0.1, 0.2],\n",
    "    'sample_size': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search_seq_ensemble(Xh_train, yh_train, param_grid, cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984b2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combos:\n",
      "    n_estimators   lr  sample_size  max_depth   r2_mean\n",
      "0           150  0.1          0.6          3  0.798998\n",
      "1           150  0.1          1.0          3  0.792579\n",
      "2           150  0.2          0.8          3  0.791567\n",
      "3           100  0.2          0.8          3  0.790717\n",
      "4           100  0.1          0.6          3  0.790011\n",
      "5           150  0.2          1.0          3  0.789513\n",
      "6           100  0.2          1.0          3  0.788360\n",
      "7           100  0.1          1.0          3  0.786865\n",
      "8           150  0.1          1.0          5  0.785773\n",
      "9           100  0.1          1.0          5  0.784163\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [ 50, 100, 150],\n",
    "    'lr': [0.01, 0.1, 0.2],\n",
    "    'sample_size': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search_seq_ensemble(Xh_train, yh_train, param_grid, cv)\n",
    "# Cuanto mas número de estimadores mejor, pero también más tiempo de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc39c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combos:\n",
      "    n_estimators   lr  sample_size  max_depth   r2_mean\n",
      "0           150  0.3          1.0          3  0.809838\n",
      "1           100  0.3          1.0          3  0.806977\n",
      "2            50  0.3          1.0          3  0.802014\n",
      "3           150  0.1          0.6          3  0.798998\n",
      "4           150  0.1          1.0          3  0.792579\n",
      "5           150  0.2          0.8          3  0.791567\n",
      "6           100  0.2          0.8          3  0.790717\n",
      "7           100  0.1          0.6          3  0.790011\n",
      "8           150  0.2          1.0          3  0.789513\n",
      "9           100  0.2          1.0          3  0.788360\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [ 50, 100, 150],\n",
    "    'lr': [0.1, 0.2, 0.3],\n",
    "    'sample_size': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search_seq_ensemble(Xh_train, yh_train, param_grid, cv)\n",
    "# Cuanto mayor la tasa de aprendizaje, más rápido aprende el modelo, pero también puede sobreajustar más rápido\n",
    "# Vamos a probar con una tasa de aprendizaje mas alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f61b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 combos:\n",
      "    n_estimators   lr  sample_size  max_depth   r2_mean\n",
      "0           150  0.3          1.0          3  0.809838\n",
      "1           100  0.3          1.0          3  0.806977\n",
      "2            50  0.3          1.0          3  0.802014\n",
      "3           150  0.1          0.6          3  0.798998\n",
      "4           150  0.1          1.0          3  0.792579\n",
      "5           150  0.2          0.8          3  0.791567\n",
      "6           100  0.2          0.8          3  0.790717\n",
      "7           100  0.1          0.6          3  0.790011\n",
      "8           150  0.2          1.0          3  0.789513\n",
      "9           100  0.2          1.0          3  0.788360\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [ 50, 100, 150],\n",
    "    'lr': [0.1, 0.2, 0.3, 0.4],\n",
    "    'sample_size': [0.6, 0.8, 1.0],\n",
    "    'max_depth': [3, 5, 7]\n",
    "}\n",
    "grid_search_seq_ensemble(Xh_train, yh_train, param_grid, cv)\n",
    "#  Con tasa de aprendizaje mayor a 0.3 el modelo empieza a sobreajustar, por lo que es mejor usar una tasa de aprendizaje menor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b27da",
   "metadata": {},
   "source": [
    "Evaluación en test con los mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de3413aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House Test R²: 0.6860433508904503\n",
      "House Test MAE: 28189.542855420998\n"
     ]
    }
   ],
   "source": [
    "best_house = SequentialEnsembleRegressor(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=100,\n",
    "    lr=0.1,\n",
    "    sample_size=0.6,\n",
    "    random_state=42,\n",
    "    max_depth=5\n",
    ")\n",
    "best_house.fit(Xh_train, yh_train)\n",
    "yh_test_pred = best_house.predict(Xh_test)\n",
    "print(\"House Test R²:\", r2_score(yh_test, yh_test_pred))\n",
    "print(\"House Test MAE:\", mean_absolute_error(yh_test, yh_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "df5bc77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinsons Test R²: 0.9203707106305425\n",
      "Parkinsons Test MAE: 1.9512256226341753\n"
     ]
    }
   ],
   "source": [
    "best_park = SequentialEnsembleRegressor(\n",
    "    estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=100,\n",
    "    lr=0.1,\n",
    "    sample_size=0.8,\n",
    "    random_state=42,\n",
    "    max_depth=7\n",
    ")\n",
    "best_park.fit(Xp_train, yp_train)\n",
    "yp_test_pred = best_park.predict(Xp_test)\n",
    "print(\"Parkinsons Test R²:\", r2_score(yp_test, yp_test_pred))\n",
    "print(\"Parkinsons Test MAE:\", mean_absolute_error(yp_test, yp_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aafb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² con early stopping: 0.6568492083061743\n",
      "MAE con early stopping: 29666.000529760913\n"
     ]
    }
   ],
   "source": [
    "class SequentialEnsembleRegressorEarlyStopping(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, estimator=None, n_estimators=50, sample_size=0.8, lr=0.1, random_state=None, patience=10, **estimator_params):\n",
    "        self.estimator = estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        self.sample_size = sample_size\n",
    "        self.lr = lr\n",
    "        self.random_state = random_state\n",
    "        self.patience = patience\n",
    "        self.estimator_params = estimator_params\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        self.models = []\n",
    "        pred = np.zeros_like(y, dtype=float)\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        n_samples = X.shape[0]\n",
    "        best_score = -np.inf\n",
    "        best_iter = 0\n",
    "        patience_counter = 0\n",
    "        val_scores = []\n",
    "        for m in range(self.n_estimators):\n",
    "            resid = y - pred\n",
    "            k = int(self.sample_size * n_samples)\n",
    "            idx = rng.choice(n_samples, k, replace=False)\n",
    "            X_sub = X.iloc[idx]\n",
    "            y_sub = resid.iloc[idx] if hasattr(resid, \"iloc\") else resid[idx]\n",
    "            model = clone(self.estimator)\n",
    "            if self.estimator_params:\n",
    "                model.set_params(**self.estimator_params)\n",
    "            model.fit(X_sub, y_sub)\n",
    "            self.models.append(model)\n",
    "            pred += self.lr * model.predict(X)\n",
    "            # Early stopping logic\n",
    "            if X_val is not None and y_val is not None:\n",
    "                val_pred = self.predict(X_val)\n",
    "                score = r2_score(y_val, val_pred)\n",
    "                val_scores.append(score)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_iter = m\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                if patience_counter >= self.patience:\n",
    "                    # Keep only the best models\n",
    "                    self.models = self.models[:best_iter+1]\n",
    "                    break\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        pred = np.zeros(X.shape[0], dtype=float)\n",
    "        for m in self.models:\n",
    "            pred += self.lr * m.predict(X)\n",
    "        return pred\n",
    "\n",
    "# Split a validation set from the training data for early stopping\n",
    "Xh_tr, Xh_val, yh_tr, yh_val = train_test_split(Xh_train, yh_train, test_size=0.2, random_state=42)\n",
    "\n",
    "es = SequentialEnsembleRegressorEarlyStopping(\n",
    "    estimator=DecisionTreeRegressor(max_depth=5),\n",
    "    n_estimators=100,\n",
    "    sample_size=0.6,\n",
    "    lr=0.1,\n",
    "    random_state=42,\n",
    "    patience=10\n",
    ")\n",
    "es.fit(Xh_tr, yh_tr, X_val=Xh_val, y_val=yh_val)\n",
    "\n",
    "yh_es = es.predict(Xh_test)\n",
    "print(\"R² con early stopping:\", r2_score(yh_test, yh_es))\n",
    "print(\"MAE con early stopping:\", mean_absolute_error(yh_test, yh_es))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2005fd8",
   "metadata": {},
   "source": [
    "================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc5d3e",
   "metadata": {},
   "source": [
    "Validación cruzada inicial con LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "14cb5a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House CV R² (LR): [0.61091079 0.77326417 0.65353687 0.82132503 0.44813318] → media: 0.661434009385928\n",
      "Parkinsons CV R² (LR): [0.20771185 0.22932094 0.12436079 0.12846975 0.13593885] → media: 0.16516043553660498\n"
     ]
    }
   ],
   "source": [
    "base_lr = SequentialEnsembleRegressor(\n",
    "    estimator=LinearRegression(),\n",
    "    n_estimators=50,\n",
    "    sample_size=0.8,\n",
    "    lr=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "scores_h_lr = cross_val_score(base_lr, Xh_train, yh_train, \n",
    "                              scoring='r2', cv=cv, n_jobs=-1)\n",
    "scores_p_lr = cross_val_score(base_lr, Xp_train, yp_train, \n",
    "                              scoring='r2', cv=cv, n_jobs=-1)\n",
    "\n",
    "print(\"House CV R² (LR):\", scores_h_lr, \"→ media:\", scores_h_lr.mean())\n",
    "print(\"Parkinsons CV R² (LR):\", scores_p_lr, \"→ media:\", scores_p_lr.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13ad15",
   "metadata": {},
   "source": [
    "Busqueda manual de mejores hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ec8cc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 combos House (LR):\n",
      "     n_estimators   lr  sample_size  fit_intercept   r2_mean\n",
      "29            50  0.1          1.0          False  0.703009\n",
      "28            50  0.1          1.0           True  0.703009\n",
      "47           100  0.1          1.0          False  0.701917\n",
      "46           100  0.1          1.0           True  0.701917\n",
      "35            50  0.2          1.0          False  0.701913\n",
      "\n",
      "Top 5 combos Parkinsons (LR):\n",
      "     n_estimators   lr  sample_size  fit_intercept   r2_mean\n",
      "33            50  0.2          0.8          False  0.165678\n",
      "32            50  0.2          0.8           True  0.165678\n",
      "27            50  0.1          0.8          False  0.165160\n",
      "26            50  0.1          0.8           True  0.165160\n",
      "51           100  0.2          0.8          False  0.165142\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'lr': [0.01, 0.1, 0.2],\n",
    "    'sample_size': [0.6, 0.8, 1.0],\n",
    "    'fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "def grid_search(X, y):\n",
    "    results = []\n",
    "    for n in param_grid['n_estimators']:\n",
    "        for lr in param_grid['lr']:\n",
    "            for s in param_grid['sample_size']:\n",
    "                for fi in param_grid['fit_intercept']:\n",
    "                    model = SequentialEnsembleRegressor(\n",
    "                        estimator=LinearRegression(),\n",
    "                        n_estimators=n,\n",
    "                        lr=lr,\n",
    "                        sample_size=s,\n",
    "                        random_state=42,\n",
    "                        fit_intercept=fi\n",
    "                    )\n",
    "                    scores = cross_val_score(\n",
    "                        model, X, y, scoring='r2', cv=cv, n_jobs=-1\n",
    "                    )\n",
    "                    results.append({\n",
    "                        'n_estimators': n,\n",
    "                        'lr': lr,\n",
    "                        'sample_size': s,\n",
    "                        'fit_intercept': fi,\n",
    "                        'r2_mean': scores.mean()\n",
    "                    })\n",
    "    return pd.DataFrame(results).sort_values('r2_mean', ascending=False)\n",
    "\n",
    "df_h_lr = grid_search(Xh_train, yh_train)\n",
    "df_p_lr = grid_search(Xp_train, yp_train)\n",
    "\n",
    "print(\"Top 5 combos House (LR):\\n\", df_h_lr.head(5))\n",
    "print(\"\\nTop 5 combos Parkinsons (LR):\\n\", df_p_lr.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece717e",
   "metadata": {},
   "source": [
    "Evaluación final del test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "282b6fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House Test (LR) R²: 0.7874562047260576 MAE: 25036.264220148114\n"
     ]
    }
   ],
   "source": [
    "#Extraer top-1 de House\n",
    "best_h = df_h_lr.iloc[0]\n",
    "best_lr_h = SequentialEnsembleRegressor(\n",
    "    estimator=LinearRegression(),\n",
    "    n_estimators=int(best_h['n_estimators']),\n",
    "    lr=float(best_h['lr']),\n",
    "    sample_size=float(best_h['sample_size']),\n",
    "    random_state=42,\n",
    "    fit_intercept=bool(best_h['fit_intercept'])\n",
    ")\n",
    "best_lr_h.fit(Xh_train, yh_train)\n",
    "yh_lr_pred = best_lr_h.predict(Xh_test)\n",
    "print(\"House Test (LR) R²:\", r2_score(yh_test, yh_lr_pred),\n",
    "      \"MAE:\", mean_absolute_error(yh_test, yh_lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f5f4612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinsons Test (LR) R²: 0.10175040386290357 MAE: 8.249848609060109\n"
     ]
    }
   ],
   "source": [
    "# Extraer top-1 de Parkinsons\n",
    "best_p = df_p_lr.iloc[0]\n",
    "best_lr_p = SequentialEnsembleRegressor(\n",
    "    estimator=LinearRegression(),\n",
    "    n_estimators=int(best_p['n_estimators']),\n",
    "    lr=float(best_p['lr']),\n",
    "    sample_size=float(best_p['sample_size']),\n",
    "    random_state=42,\n",
    "    fit_intercept=bool(best_p['fit_intercept'])\n",
    ")\n",
    "best_lr_p.fit(Xp_train, yp_train)\n",
    "yp_lr_pred = best_lr_p.predict(Xp_test)\n",
    "print(\"Parkinsons Test (LR) R²:\", r2_score(yp_test, yp_lr_pred),\n",
    "      \"MAE:\", mean_absolute_error(yp_test, yp_lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989ba89",
   "metadata": {},
   "source": [
    "EarlyStoping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f3e2f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House (LR + early stopping) R²: 0.7914746899568399\n",
      "House (LR + early stopping) MAE: 24716.9139875049\n"
     ]
    }
   ],
   "source": [
    "es_lr = SequentialEnsembleRegressorEarlyStopping(\n",
    "    estimator=LinearRegression(),\n",
    "    n_estimators=100,\n",
    "    sample_size=1.0,      # en tu grid buscaste sample_size=1.0\n",
    "    lr=0.1,\n",
    "    random_state=42,\n",
    "    patience=10,          # tolera 10 iteraciones sin mejora\n",
    "    fit_intercept=True    # o False, según tu mejor combo\n",
    ")\n",
    "es_lr.fit(Xh_train, yh_train)\n",
    "yh_es_lr = es_lr.predict(Xh_test)\n",
    "\n",
    "print(\"House (LR + early stopping) R²:\", r2_score(yh_test, yh_es_lr))\n",
    "print(\"House (LR + early stopping) MAE:\", mean_absolute_error(yh_test, yh_es_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4b0a26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parkinsons (LR + early stopping) R²: 0.1430420079518817\n",
      "Parkinsons (LR + early stopping) MAE: 8.11477793461102\n"
     ]
    }
   ],
   "source": [
    "es_lr_p = SequentialEnsembleRegressorEarlyStopping(\n",
    "    estimator=LinearRegression(),\n",
    "    n_estimators=100,\n",
    "    sample_size=0.8,\n",
    "    lr=0.2,\n",
    "    random_state=42,\n",
    "    patience=10,\n",
    "    fit_intercept=True\n",
    ")\n",
    "es_lr_p.fit(Xp_train, yp_train)\n",
    "yp_es_lr = es_lr_p.predict(Xp_test)\n",
    "\n",
    "print(\"Parkinsons (LR + early stopping) R²:\", r2_score(yp_test, yp_es_lr))\n",
    "print(\"Parkinsons (LR + early stopping) MAE:\", mean_absolute_error(yp_test, yp_es_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f04375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
